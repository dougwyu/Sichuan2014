---
title: "Sichuan2014_metabarcode pipeline"
author: "Xiaoyang Wang and Douglas Yu"
date: "07/07/2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

Make sure that Source option is set to `Chunk output in Console` and do not select `Show Previews inline`

## Tentative conclusions

1) Mosaic forest has higher species richness and higher Shannon richness than the monospecies plantations:  JC, EC, and BB (marginal diff over BB)
2) Mosaic forest composition is more similar to Natural forest than any of the monospecies plantations are to Natural forest
3) The source of the beta diversity in this system is entirely turnover, which means that each of the monospecies plantations has its own set of species

# start R analysis
```{r setup, packages}
library(ape)
library(tidyverse) 
library(vegan)
library(beanplot)
library(car)
library(iNEXT)
library(iNextPD)
library(ade4)
library(boral)
library(mvabund)
library(RColorBrewer)
library(betapart)
library(forcats)
library(stringr)
library(SpeciesMix)
library(beepr)
library(corrplot)
library(data.table)
library(ggplot2)
library(metacoder)
library(tibble)

#source("https://bioconductor.org/biocLite.R")
#biocLite("phyloseq")
library(phyloseq)

# library(devtools)
# install_github("tobiasgf/lulu")  
library(lulu)

sessionInfo()
```

#After CROP clustering with 97sim
#run following commands on terminal for getting match_list
cd Documents/kiz/ecec/2014-GFGP/MBC-miseq/Eco_analysis/2014MBC_CROP97_3507otus/1lulu_3507
vsearch --usearch_global 2libs_CROP97.cluster3507.fasta --db 2libs_CROP97.cluster3507.fasta --self --id .84 --iddef 1 --userout match_list.txt -userfields query+target+id --maxaccepts 0 --query_cov .9 --maxhits 10

# using match list for lulu
```{r code for lulu, eval=FALSE, include=FALSE}
matchlist <- read.table("lulu_3507/match_list.txt", header=FALSE,as.is=TRUE, stringsAsFactors=FALSE) 
comLuLu <- read.table("lulu_3507/2libs_CROP97_merge_otu3507.txt", header= T, sep = "\t")

str(comLuLu)
rname <- comLuLu[,1]
comLuLu <- comLuLu[,-1]
comLuLu <- sapply(comLuLu, function(x) as.numeric(x))
rownames(comLuLu) <- rname
comLuLu <- as.data.frame(comLuLu)

curated_result <- lulu(comLuLu, matchlist) # equals 
#curated_result <- lulu(comLuLu, matchlist, minimum_ratio_type = "min", minimum_ratio = 1, minimum_match = 84, minimum_relative_cooccurence = 0.95)

new_table_lulu <- curated_result$curated_table
write.table(new_table_lulu, "lulu_3507/2014MBC_otu1506.txt", sep = "\t")

```

#we do phyloseq after lulu
```{r phyloseq, eval=FALSE, include=FALSE}
########## filter small OTUs, phyloseq ##
communityAll_t <- new_table_lulu

communityAll <- t(communityAll_t)
TotalCounts <- c(colSums(communityAll))

tdt = data.table(colnames(communityAll),TotalCounts = colSums(communityAll),OTU = colnames(communityAll))

ggplot(tdt, aes(TotalCounts)) + 
  geom_histogram() + 
  ggtitle("Histogram of Total Counts")

tdt[(TotalCounts <= 0), .N]
tdt[(TotalCounts <= 1), .N]
tdt[(TotalCounts <= 2), .N]

taxcumsum = tdt[, .N, by = TotalCounts]
setkey(taxcumsum, TotalCounts)
taxcumsum[, CumSum := cumsum(N)]
# Define the plot
pCumSum = ggplot(taxcumsum, aes(TotalCounts, CumSum)) + 
  geom_point() +
  xlab("Filtering Threshold, Minimum Total Counts") +
  ylab("OTUs Filtered") +
  ggtitle("OTUs that would be filtered vs. the minimum count threshold")
pCumSum
pCumSum + xlim(0, 40)
pCumSum + xlim(0, 50)
pCumSum + xlim(0, 60)
pCumSum + xlim(0, 80)
pCumSum + xlim(0, 100)
pCumSum + xlim(0, 200)
pCumSum + xlim(0, 300)
pCumSum + xlim(0, 400)

## phyloseq-class experiment-level object
## otu_table()   OTU Table:         [ 3426 taxa and 34 samples ]
## sample_data() Sample Data:       [ 34 samples by 11 sample variables ]
## tax_table()   Taxonomy Table:    [ 3426 taxa by 7 taxonomic ranks ]
## phy_tree()    Phylogenetic Tree: [ 3426 tips and 3424 internal nodes ]

commMBC.20 <- communityAll[ ,colSums(communityAll)>=20] ## 731 otus remain
commMBC.20 <- commMBC.20[ rowSums(commMBC.20)>0,]
rowSums(commMBC.20)
commMBC20copies <- t(commMBC.20)

commMBC.44 <- communityAll[ ,colSums(communityAll)>=44] # 594 otus remain
commMBC.44 <- commMBC.44[ rowSums(commMBC.44)>0,]
rowSums(commMBC.44)
commMBC44copies <- t(commMBC.44)

write.table(commMBC20copies, file = "2phyloseq1506/2014MBC_20reads_otu731.txt", sep = "\t", row.names = TRUE, col.names = TRUE)
write.table(commMBC44copies, file = "2phyloseq1506/2014MBC_44reads_otu594.txt", sep = "\t", row.names = TRUE, col.names = TRUE)

```

## commnunity analyses start from here
```{r load and format data for community analyses}

inputfile <- "./data/2014MBC_44reads_otu543_LandsatEnv.txt" # post phyloseq filtering and filtering for trees, using final bioinformatics pipeline with vsearch and RDP Classifier and phyloseq at min20reads, with landsat data

# command from readr package, with options on formatting the columns
gfgMB <- read_tsv(
   inputfile, col_names = TRUE, na = "NA",
   col_types = cols(
     Site = col_character(),
     Habitat = col_factor(c("BB", "CL", "EC", "JC", "MF", "NF")),
     Type = col_factor(c("1", "2", "3", "4", "5", "6")),
     Altitude = col_integer(),
     sampling_time = col_date(format = "%d/%m/%Y"),
     weather_value = col_factor(c("cloudy", "sunny", "rainy")),
     Landsat_value = col_factor(c("1", "2", "3", "4", "5", "6")),
     longitude = col_double(),
     latitude = col_double(),
     Elevation_m = col_integer()
     )
 )

gfgMB <- tbl_df(gfgMB)

# with(gfgMB, plot(Altitude ~ Elevation_m, col=as.numeric(Habitat)))  # Altitude variable is not reliable;  use Elevation_m instead, which is calculated from DEM
```

```{r environment dataset}
# make environment dataset
habitat <- gfgMB %>% dplyr::select(Site:Simpson_evenness_index)
habitat <- habitat %>% dplyr::filter(!is.na(Habitat)) # remove taxonomy rows
colnames(habitat)[11:80] <- paste0("x", colnames(habitat)[11:80]) # column names need to start with a letter
```

```{r community build}
community <- gfgMB %>% dplyr::select(starts_with("Cluster"))
# otuvector <- colnames(community)
community_t <- t(community)
community_t <- as.data.frame(community_t)
community_t <- rownames_to_column(community_t)
colnames(community_t) <- c("otu", gfgMB$Site) # add column names

#communityAll_t <- community_t %>% dplyr::filter(phylum=="Arthropoda")
#communityAll_t <- community_t %>% dplyr::select(-c(kingdom:species))
communityAll <- t(community_t)
colvector <- communityAll[1,] # make a vector of the first row, which has the otu names
communityAll <- as.data.frame(communityAll)
colnames(communityAll) <-  colvector # add the otu names to the column names
communityAll <- communityAll[-1,] # remove first row, which has the column names
# convert the columns to numeric from factor
# http://stackoverflow.com/questions/2288485/how-to-convert-a-data-frame-column-to-numeric-type
communityAll <- sapply(communityAll, function(x) as.numeric(as.character(x))) # sapply applies a function to each column, and the function is:  function(x) as.numeric(as.character(x)).  Cannot convert factors to numeric directly. first convert to character, then to numeric
communityAll <- as.data.frame(communityAll) # then convert to df
```

# visualise a histogram of read number per OTU
```{r histogram of otu read numbers}
##### calculate distribution of read numbers per OTU to set minimum number 
otureads <- c(colSums(communityAll)) # list of the reads per OTU
sum(otureads) ## 1,900,539 reads total 
otureads[otureads>5000] <- 5000 # to make the histogram readable
otuhist <- hist(otureads, breaks = 100)
text(otuhist$mids, otuhist$counts, cex = 0.5, otuhist$counts, adj = c(.5, -.5), col = "blue3")
```

# Starting ecological analysis
Filter out sites with (1) low reads (<= 100), (2) very low numbers of species
```{r filter out sites }
community <- communityAll
#community <- t(new_table_lulu)
community <- as.data.frame(community)
#sort(colSums(community))
community[community < 5] <- 0 # set small cells to 0.

habitat$rowsums <- rowSums(community)
habitat$sprichness <- specnumber(community, MARGIN = 1) # number of species per site
# keep only sites that have more than 100 reads (removed 2, still remain 68)
community <- community %>% dplyr::filter(habitat$rowsums > 100)
habitatN <- habitat %>% dplyr::filter(habitat$rowsums > 100)
rowSums(community)

# keep only sites that have >=5 species (removed 68 - 61 = 7 sites)
community <- community %>% dplyr::filter(habitatN$sprichness >= 5)
habitatN <- habitatN %>% dplyr::filter(habitatN$sprichness >= 5)
#sort(colSums(community))
habitatN <- droplevels(habitatN)
community <- community[, colSums(community)>=20]
#Cluster31064  Cluster334816  Cluster672922  Cluster932857  Cluster989447  Cluster273565 Cluster1265861

```

```{r save datasets for GDM, eval=FALSE, include=FALSE}
write.table(community, "GDM_community.txt", sep = "\t")
write.table(habitatN, "GDM_environment.txt", sep = "\t")
```

```{r beanplot of reads number by habitat}
beanplot(rowSums(community)~habitatN$Habitat, col = c("grey", "white"), xlab = "Habitat type", ylab = "Reads number")
# Kampstra, P. Beanplot: A Boxplot Alternative for Visual Comparison of Distributions. Journal of Statistical Software, Code Snippets 28(1). 1-9 (2008) 

nboot <- 999 # set to 999 for publication
# base model with no levels combined
reads.glm <- manyglm(rowSums(community) ~ habitatN$Habitat)
plot(reads.glm)
anova(reads.glm, cor.type = "shrink", test = "score", show.time = "all", nBoot = nboot)  # p = 0.04, df = 5, score = 8.671, nBoot = 999, 1 min. all reads number are not significantly defferent from each other

```

#we used the taxonomic assignment (RDP classifier) results to built a taxon distribution of all OTUs
```{r metacoder, warning=FALSE}
#### for otus taxa tree

mbc_otus <- read.table("data/forMetacoder/2014MBC_otu536_tax.txt", header = T, sep = "\t")
mbc_samples <- read.table("data/forMetacoder/2014MBC_sample536.txt", header = T, sep = "\t")

mbc_otus[mbc_otus>1] <- 1 # using presence/absance data

#str(mbc_otus)
#str(mbc_samples)
## change data type 
mbc_otus$OTU_id <- as.character(mbc_otus$OTU_id)
mbc_otus$lineage <- as.character(mbc_otus$lineage)
mbc_samples$Site <- as.character(mbc_samples$Site)
mbc_samples$Habitat <- as.character(mbc_samples$Habitat)
##
mbc_otus <- as_tibble(mbc_otus)
mbc_samples <- as_tibble(mbc_samples)
#print(mbc_otus)
#print(mbc_samples)

obj <- parse_tax_data(mbc_otus, class_cols = "lineage", class_sep = ";",
                      class_key = c(tax_rank = "info", tax_name = "taxon_name"),
                      class_regex = "^(.+)__(.+)$")

# This returns a taxmap object. The taxmap class is designed to store any number of tables, lists, or vectors associated with taxonomic information and facilitate manipulating the data in a cohesive way. Here is what that object looks like:

print(obj) # or click on the object in the Environment pane

# accounting for un-even sampling
obj$data$tax_data <- calc_obs_props(obj, "tax_data")

print(obj)

# Getting per-taxon information
# Currently, we have values for the abundance of each OTU, not each taxon. To get information on the taxa, we can sum the abundance per-taxon like so:
obj$data$tax_abund <- calc_taxon_abund(obj, "tax_data",
                                       cols = mbc_samples$Site)
print(obj)
# Note that there is now an additional table with one row per taxon.
# We can also easily calculate the number of samples have reads for each taxon:
obj$data$tax_occ <- calc_n_samples(obj, "tax_abund", groups = mbc_samples$Habitat)
print(obj)

# Plotting taxonomic data
# Now that we have per-taxon information, we can plot the information using heat trees. The code below plots the number of “Nose” samples that have reads for each taxon. It also plots the number of OTUs assigned to each taxon in the overall dataset.

heat_tree(obj, 
          node_label = obj$taxon_names(),
          node_size = obj$n_obs(),
          node_color = obj$data$tax_occ$NF, 
          node_size_axis_label = "OTU count",
          node_color_axis_label = "Samples with reads")

# Comparing any number of treatments/groups
obj$data$diff_table <- compare_groups(obj, dataset = "tax_abund",
                                      cols = mbc_samples$Site,
                                      groups = mbc_samples$Habitat)
print(obj$data$diff_table)
heat_tree_matrix(obj,
                 dataset = "diff_table",
                 node_size = n_obs,
                 node_label = taxon_names,
                 node_color = log2_median_ratio,
                 node_color_range = diverging_palette(),
                 node_color_trans = "linear",
                 node_color_interval = c(-3, 3),
                 edge_color_interval = c(-3, 3),
                 node_size_axis_label = "Number of OTUs",
                 node_color_axis_label = "Log2 ratio median proportions")


# page(compare_groups) #check codes of compare_groups, change "median" to "mean"

##### remove CL group to see difference in  forest 
otus_without_CL <- mbc_otus %>% dplyr::select(-c(CL01:CL16))
samples_without_CL <- mbc_samples %>% dplyr::filter(mbc_samples$Habitat %in% c("BB", "EC", "JC", "MF", "NF"))

print(otus_without_CL)
print(samples_without_CL)
#str(otus_without_CL)
#str(samples_without_CL)
objF <- parse_tax_data(otus_without_CL, class_cols = "lineage", class_sep = ";",
                      class_key = c(tax_rank = "info", tax_name = "taxon_name"),
                      class_regex = "^(.+)__(.+)$")

# This returns a taxmap object. The taxmap class is designed to store any number of tables, lists, or vectors associated with taxonomic information and facilitate manipulating the data in a cohesive way. Here is what that object looks like:

print(objF) # or click on the object in the Environment pane

# removing low abundance counts
#objF$data$tax_data <- zero_low_counts(objF, "tax_data", min_count = 5)
#no_reads <- rowSums(objF$data$tax_data[, samples_without_CL$Site]) == 0
#sum(no_reads)
#objF <- filter_obs(objF, "tax_data", ! no_reads, drop_taxa = TRUE)
#print(objF)

# accounting for un-even sampling
objF$data$tax_data <- calc_obs_props(objF, "tax_data")

print(objF)

# Getting per-taxon information
# Currently, we have values for the abundance of each OTU, not each taxon. To get information on the taxa, we can sum the abundance per-taxon like so:
objF$data$tax_abund <- calc_taxon_abund(objF, "tax_data",
                                       cols = samples_without_CL$Site)
print(objF)
# Note that there is now an additional table with one row per taxon.
# We can also easily calculate the number of samples have reads for each taxon:
objF$data$tax_occ <- calc_n_samples(objF, "tax_abund", groups = samples_without_CL$Habitat)
print(objF)

# Plotting taxonomic data
# Now that we have per-taxon information, we can plot the information using heat trees. The code below plots the number of “Nose” samples that have reads for each taxon. It also plots the number of OTUs assigned to each taxon in the overall dataset.

heat_tree(objF, 
          node_label = objF$taxon_names(),
          node_size = objF$n_obs(),
          node_color = objF$data$tax_occ$NF, 
          node_size_axis_label = "OTU count",
          node_color_axis_label = "Samples with reads")

# Comparing any number of treatments/groups
objF$data$diff_table <- compare_groups(objF, dataset = "tax_abund",
                                      cols = samples_without_CL$Site,
                                      groups = samples_without_CL$Habitat)
print(objF$data$diff_table)
heat_tree_matrix(objF,
                 dataset = "diff_table",
                 node_size = n_obs,
                 node_label = taxon_names,
                 node_color = log2_median_ratio,
                 node_color_range = diverging_palette(),
                 node_color_trans = "linear",
                 node_color_interval = c(-3, 3),
                 edge_color_interval = c(-3, 3),
                 node_size_axis_label = "Number of OTUs",
                 node_color_axis_label = "Log2 ratio median proportions")


```

# Alpha Diversity
```{r make presence/absence dataset}
communityB <- community
communityB[communityB>1] <- 1 # binary
rownames(communityB) # 61 rows = sites
```

```{r beanplot}
#beanplot(specnumber(communityB)~habitatN$Habitat, col = c("grey", "white"))
beanplot(specnumber(communityB)~habitatN$Habitat, col = c("grey", "white"), xlab = "Habitat type", ylab = "Species richness")
```

```{r t-test for observed species richness}
BB <- communityB %>% dplyr::filter(habitatN$Habitat %in% c("BB"))
CL <- communityB %>% dplyr::filter(habitatN$Habitat %in% c("CL"))
EC <- communityB %>% dplyr::filter(habitatN$Habitat %in% c("EC"))
JC <- communityB %>% dplyr::filter(habitatN$Habitat %in% c("JC"))
MF <- communityB %>% dplyr::filter(habitatN$Habitat %in% c("MF"))
NF <- communityB %>% dplyr::filter(habitatN$Habitat %in% c("NF"))

BB_obs <- rowSums(BB)
CL_obs <- rowSums(CL)
EC_obs <- rowSums(EC)
JC_obs <- rowSums(JC)
MF_obs <- rowSums(MF)
NF_obs <- rowSums(NF)

t.test(BB_obs, CL_obs)
t.test(BB_obs, EC_obs)
t.test(BB_obs, JC_obs)
t.test(BB_obs, MF_obs)
t.test(BB_obs, NF_obs)
t.test(CL_obs, EC_obs)
t.test(CL_obs, JC_obs)
t.test(CL_obs, MF_obs)
t.test(CL_obs, NF_obs)
t.test(EC_obs, JC_obs)
t.test(EC_obs, MF_obs)
t.test(EC_obs, NF_obs)
t.test(JC_obs, MF_obs)
t.test(JC_obs, NF_obs)
t.test(MF_obs, NF_obs)

p_values <- c(0.0244, 0.2402, 0.1078, 0.7774, 0.2095, 0.0027, 0.0004, 0.0142, 0.6047, 0.7341, 0.3663, 0.0429, 0.1877, 0.0202, 0.1514)
p_values.corr.fdr<-p.adjust(p_values, method = "fdr", n = length(p_values)) 
p_values.corr.fdr
# 0.0732000 0.3275455 0.2310000 0.7774000 0.3142500 0.0202500 0.0060000 0.0710000
# 0.6977308 0.7774000 0.4578750 0.1072500 0.3128333 0.0732000 0.2838750
```

# traditional Chao
```{r specpool, }
######## otu table with original reads number
(pool1 <- specpool(communityB, habitatN$Habitat))

```

   Species     chao  chao.se     jack1 jack1.se    jack2     boot   boot.se  n
BB      83 185.9796 39.89775 132.71429 20.90210 165.8095 104.1117  8.989364  7
CL     194 336.1658 37.44452 295.73333 32.32777 358.8143 238.0445 15.679575 15
EC      64 115.4592 22.33722  99.14286 16.06619 120.0952  79.3403  7.646678  7
JC      85 209.6154 48.52236 139.00000 23.08246 177.7556 107.5053 10.816630 10
MF     119 405.5079 98.01090 203.44444 33.92075 267.8056 153.4993 14.358124  9
NF     210 507.3394 72.71267 346.61538 48.44615 445.4744 266.7256 22.180423 13

```{r barchart for estimating value}
es_value <- c(185.9796, 115.4592, 209.6154, 405.5079, 336.1658, 507.3394)
se <- c(39.89775, 22.33722, 48.52236, 98.01090, 37.44452, 72.71267)

error.bar <- function(x, y, upper, lower=upper, length=0.1,...){
if(length(x) != length(y) | length(y) !=length(lower) | length(lower) != length(upper))
stop("vectors must be same length")
arrows(x,y+upper, x, y-lower, angle=90, code=3, length=length, ...)
}

par(mfrow=c(1,2))
bar_es <- barplot(es_value, names.arg = c("BB", "EC", "JC", "MF", "CL", "NF"), col = "lightblue", ylim = c(0, 600), border = NA, ylab = "Species richness estimates")
error.bar(bar_es,es_value, se)
par(mfrow=c(1,1))

```

```{r Welch-t test for Chao}
############ This function (t.test2) will calculate Welch's test
t.test2 <- function(m1, m2, s1, s2, n1, n2, m0=0, equal.variance=FALSE)
{
  if( equal.variance==FALSE ) 
  {
    se <- sqrt( (s1^2/n1) + (s2^2/n2) )
    # welch-satterthwaite df
    df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
  } else
  {
    # pooled standard deviation, scaled by the sample sizes
    se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) ) 
    df <- n1+n2-2
  }      
  t <- (m1-m2-m0)/se 
  dat <- c(m1-m2, se, t, round(df,1), 2*pt(-abs(t),df))    
  names(dat) <- c("Difference of means", "Std Error", "t", "df", "p-value")
  return(dat) 
}

pool1[1, 9]

# t test for BB and CL
t.test2(pool1[1, 2], pool1[2, 2], pool1[1, 3]*sqrt(pool1[1, 9]), pool1[2, 3]*sqrt(pool1[2, 9]), pool1[1, 9], pool1[2, 9])

# t test for BB and EC
t.test2(pool1[1, 2], pool1[3, 2], pool1[1, 3]*sqrt(pool1[1, 9]), pool1[3, 3]*sqrt(pool1[3, 9]), pool1[1, 9], pool1[3, 9])

# t test for BB and JC
t.test2(pool1[1, 2], pool1[4, 2], pool1[1, 3]*sqrt(pool1[1, 9]), pool1[4, 3]*sqrt(pool1[4, 9]), pool1[1, 9], pool1[4, 9])

# t test for BB and MF
t.test2(pool1[1, 2], pool1[5, 2], pool1[1, 3]*sqrt(pool1[1, 9]), pool1[5, 3]*sqrt(pool1[5, 9]), pool1[1, 9], pool1[5, 9])

# t test for BB and NF
t.test2(pool1[1, 2], pool1[6, 2], pool1[1, 3]*sqrt(pool1[1, 9]), pool1[6, 3]*sqrt(pool1[6, 9]), pool1[1, 9], pool1[6, 9])

# t test for CL and EC
t.test2(pool1[2, 2], pool1[3, 2], pool1[2, 3]*sqrt(pool1[2, 9]), pool1[3, 3]*sqrt(pool1[3, 9]), pool1[2, 9], pool1[3, 9])

# t test for CL and JC
t.test2(pool1[2, 2], pool1[4, 2], pool1[2, 3]*sqrt(pool1[2, 9]), pool1[4, 3]*sqrt(pool1[4, 9]), pool1[2, 9], pool1[4, 9])

# t test for CL and MF
t.test2(pool1[2, 2], pool1[5, 2], pool1[2, 3]*sqrt(pool1[2, 9]), pool1[5, 3]*sqrt(pool1[5, 9]), pool1[2, 9], pool1[5, 9])

# t test for CL and NF
t.test2(pool1[2, 2], pool1[6, 2], pool1[2, 3]*sqrt(pool1[2, 9]), pool1[6, 3]*sqrt(pool1[6, 9]), pool1[2, 9], pool1[6, 9])

# t test for EC and JC
t.test2(pool1[3, 2], pool1[4, 2], pool1[3, 3]*sqrt(pool1[3, 9]), pool1[4, 3]*sqrt(pool1[4, 9]), pool1[3, 9], pool1[4, 9])

# t test for EC and MF
t.test2(pool1[3, 2], pool1[5, 2], pool1[3, 3]*sqrt(pool1[3, 9]), pool1[5, 3]*sqrt(pool1[5, 9]), pool1[3, 9], pool1[5, 9])

# t test for EC and NF
t.test2(pool1[3, 2], pool1[6, 2], pool1[3, 3]*sqrt(pool1[3, 9]), pool1[6, 3]*sqrt(pool1[6, 9]), pool1[3, 9], pool1[6, 9])

# t test for JC and MF
t.test2(pool1[4, 2], pool1[5, 2], pool1[4, 3]*sqrt(pool1[4, 9]), pool1[5, 3]*sqrt(pool1[5, 9]), pool1[4, 9], pool1[5, 9])

# t test for JC and NF
t.test2(pool1[4, 2], pool1[6, 2], pool1[4, 3]*sqrt(pool1[4, 9]), pool1[6, 3]*sqrt(pool1[6, 9]), pool1[4, 9], pool1[6, 9])

# t test for MF and NF
t.test2(pool1[5, 2], pool1[6, 2], pool1[5, 3]*sqrt(pool1[5, 9]), pool1[6, 3]*sqrt(pool1[6, 9]), pool1[5, 9], pool1[6, 9])

# BB_CL, BB_EC, BB_JC, BB_MF, BB_NF, CL_EC, CL_JC, CL_MF, CL_NF, EC_JC, EC_MF, EC_NF, JC_MF, JC_NF, MF_NF
p_values <- c(0.0144, 0.1530, 0.7236, 0.0613, 0.0012, 0.0001, 0.0515, 0.4953, 0.0519, 0.1041, 0.0182, 0.0001, 0.0933, 0.0028, 0.4543)
p_values.corr.fdr<-p.adjust(p_values, method = "fdr", n = length(p_values)) 
p_values.corr.fdr
# 0.0432000 0.1912500 0.7236000 0.1021667 0.0060000 0.0007500 0.0973125 0.5306786
# 0.0973125 0.1419545 0.0455000 0.0007500 0.1399500 0.0105000 0.5241923

```

# Interpolation and extrapolation of Hill number 
```{r iNEXT}
# http://chao.stat.nthu.edu.tw/wordpress/wp-content/uploads/software/iNEXT_UserGuide.pdf

cname <- c("BB","CL","EC","JC","MF","NF")

comm4inext_abun <- matrix(c(colSums(BB), colSums(CL), colSums(EC), colSums(JC), colSums(MF), colSums(NF)), ncol = 6)

colnames(comm4inext_abun) <- cname
colnameBB <- colnames(BB)
rownames(comm4inext_abun) <- colnameBB

comm4inext <- rbind(c(nrow(BB), nrow(CL), nrow(EC), nrow(JC), nrow(MF), nrow(NF)), comm4inext_abun) #
#comm4inext

confnum=0.95 # set confidence here
outcomm0 <- iNEXT(comm4inext, q=0, conf=confnum, datatype="incidence_freq")
# Hill numbers (q):  0 = sp richness, 1 = Shannon, 2 = inverse Simpson
outcomm0$DataInfo
ChaoRichness(comm4inext, datatype="incidence_freq") # same as specpool results, so i trust that we have done this correctly
ChaoShannon(comm4inext, datatype="incidence_freq")

outI <- iNEXT(comm4inext, q=c(0,1,2), conf=confnum, datatype="incidence_freq")
# Sample‐size‐based R/E curves, separating by "site"
ggiNEXT(outI, type=1, facet.var="site") +theme_bw(base_size = 18)
# Sample‐size‐based R/E curves, separating by "order"
ggiNEXT(outI, type=1, facet.var="order")+theme_bw(base_size = 18)

```

```{r iNextPD }
commPD <- communityB
#remove 3 OTUs with very long branches
commPD$Cluster418132 <- NULL
commPD$Cluster636975 <- NULL
commPD$Cluster549885 <- NULL

BB <- commPD %>% dplyr::filter(habitatN$Habitat %in% c("BB"))
CL <- commPD %>% dplyr::filter(habitatN$Habitat %in% c("CL"))
EC <- commPD %>% dplyr::filter(habitatN$Habitat %in% c("EC"))
JC <- commPD %>% dplyr::filter(habitatN$Habitat %in% c("JC"))
MF <- commPD %>% dplyr::filter(habitatN$Habitat %in% c("MF"))
NF <- commPD %>% dplyr::filter(habitatN$Habitat %in% c("NF"))
comm4inextPD <- matrix(c(colSums(BB), colSums(CL), colSums(EC), colSums(JC), colSums(MF), colSums(NF)), ncol = 6)

colnames(comm4inextPD) <- cname
colnameBB <- colnames(BB)
rownames(comm4inextPD) <- colnameBB

MLtree.tre <- read.table("./data/2014MBC_535otu-2collembola_align533.newick")
ML.tre <- ade4::newick2phylog(MLtree.tre$V1)
ML.lab <- rownames(comm4inextPD)

#rownames(comm4inext_abun)
BBnames <- habitatN %>% dplyr::filter(habitatN$Habitat %in% c("BB"))
CLnames <- habitatN %>% dplyr::filter(habitatN$Habitat %in% c("CL"))
ECnames <- habitatN %>% dplyr::filter(habitatN$Habitat %in% c("EC"))
JCnames <- habitatN %>% dplyr::filter(habitatN$Habitat %in% c("JC"))
MFnames <- habitatN %>% dplyr::filter(habitatN$Habitat %in% c("MF"))
NFnames <- habitatN %>% dplyr::filter(habitatN$Habitat %in% c("NF"))

rownames(BB) <- BBnames$Site
rownames(CL) <- CLnames$Site
rownames(EC) <- ECnames$Site
rownames(JC) <- JCnames$Site
rownames(MF) <- MFnames$Site
rownames(NF) <- NFnames$Site

BBnames$Site

#commB <- list(BB.Site = t(BB), CL.Site = t(CL), EC.Site = t(EC), JC.Site = t(JC), MF.Site = t(MF), NF.Site = t(NF))
commB <- list(BB = t(BB), CL = t(CL), EC = t(EC), JC = t(JC), MF = t(MF), NF = t(NF))


out <- iNextPD(commB, ML.lab, ML.tre, q=c(0, 1, 2), datatype="incidence_raw", endpoint = 30, se = TRUE)
# Sample‐size‐based R/E curves, separating by "site""
ggiNEXT(out, type=1, facet.var="site") +theme_bw(base_size = 18)
# Sample‐size‐based R/E curves, separating by "order"
ggiNEXT(out, type=1, facet.var="order")+theme_bw(base_size = 18)
# display black‐white theme
ggiNEXT(out, type=1, facet.var="order", grey=TRUE)

table.phylog(comm4inextPD, ML.tre, csize=2, f.phylog=0.7)

```

# Beta diversity turnover versus nestedness
## Run tabasco before removing zerotons and singletons
```{r tabasco}
community.jmds <- metaMDS(communityB, distance = "jaccard", trymax = 40, binary=TRUE)
community.jmds <- metaMDS(communityB, distance = "jaccard", binary = TRUE, previous.best = community.jmds)  # doesn't converge well, with final stress > 0.20
stressplot(community.jmds)
tabasco(community, use = community.jmds, labCol = habitatN$Habitat, col = brewer.pal(3, "Oranges"))
```

## Betapart analysis before removing zerotons and singletons
```{r betapart, warning=FALSE}
communityBbetapart <- bind_cols(habitatN, communityB) 
communityBbetapart <- communityBbetapart %>% dplyr::select(-c(Habitat:sprichness))

JCNF <- communityBbetapart %>% dplyr::filter(habitatN$Habitat %in% c("JC", "NF")) %>% column_to_rownames(var="Site")
BBNF <- communityBbetapart %>% dplyr::filter(habitatN$Habitat %in% c("BB", "NF")) %>% column_to_rownames(var="Site")
CLNF <- communityBbetapart %>% dplyr::filter(habitatN$Habitat %in% c("CL", "NF")) %>% column_to_rownames(var="Site")
ECNF <- communityBbetapart %>% dplyr::filter(habitatN$Habitat %in% c("EC", "NF")) %>% column_to_rownames(var="Site")
MFNF <- communityBbetapart %>% dplyr::filter(habitatN$Habitat %in% c("MF", "NF")) %>% column_to_rownames(var="Site")

JCNF.multi.dist <- beta.multi(JCNF, index.family="jac")
BBNF.multi.dist <- beta.multi(BBNF, index.family="jac")
CLNF.multi.dist <- beta.multi(CLNF, index.family="jac")
ECNF.multi.dist <- beta.multi(ECNF, index.family="jac")
MFNF.multi.dist <- beta.multi(MFNF, index.family="jac")

multi.all <- list(JCNF = JCNF.multi.dist, BBNF = BBNF.multi.dist, CLNF = CLNF.multi.dist, ECNF =  ECNF.multi.dist, MFNF = MFNF.multi.dist)


ALL.dist <- communityBbetapart %>% column_to_rownames(var="Site") %>% beta.pair(index.family="jac")
ALL.dist.subset <- ALL.dist[["beta.jne"]]
ALL.dist.jne.jmds <- metaMDS(ALL.dist.subset)
ALL.dist.jne.jmds <- metaMDS(ALL.dist.subset, previous.best = ALL.dist.jne.jmds)
stressplot(ALL.dist.jne.jmds)
ALL.dist.subset <- ALL.dist[["beta.jtu"]]
ALL.dist.jtu.jmds <- metaMDS(ALL.dist.subset)
ALL.dist.jtu.jmds <- metaMDS(ALL.dist.subset, previous.best = ALL.dist.jne.jmds)
stressplot(ALL.dist.jtu.jmds)


# , ylim = c(-0.5, 0.5), xlim = c(-0.4, 0.4)
par(mfrow=c(2,2))
colvec <- brewer.pal(5, "Set1")
with(habitatN, ordisurf(community.jmds, sprichness, main="All beta diversity", cex=0.5, col = "white"),  ylim = c(-0.5, 0.5))
# plot(community.jmds, main = "All beta diversity", ylim = c(-0.4, 0.4))
    with(habitatN, ordispider(community.jmds, Habitat, cex=.5, draw="polygon", col=as.character(colvec[3]), alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("BB"))))
    with(habitatN, ordispider(community.jmds, Habitat, cex=.5, draw="polygon", col=as.character(colvec[1]), alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("CL"))))
    with(habitatN, ordispider(community.jmds, Habitat, cex=.5, draw="polygon", col=as.character(colvec[3]), alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("EC"))))
    with(habitatN, ordispider(community.jmds, Habitat, cex=.5, draw="polygon", col=as.character(colvec[3]), alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("JC"))))
    with(habitatN, ordispider(community.jmds, Habitat, cex=.5, draw="polygon", col="darkblue", alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("MF"))))
    with(habitatN, ordispider(community.jmds, Habitat, cex=.5, draw="polygon", col="darkblue", alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("NF"))))

plot(ALL.dist.jtu.jmds, main = "Turnover beta diversity only", ylim = c(-0.5, 0.5))
    with(habitatN, ordispider(ALL.dist.jtu.jmds, Habitat, cex=.5, draw="polygon", col=as.character(colvec[3]), alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("BB"))))
    with(habitatN, ordispider(ALL.dist.jtu.jmds, Habitat, cex=.5, draw="polygon", col=as.character(colvec[1]), alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("CL"))))
    with(habitatN, ordispider(ALL.dist.jtu.jmds, Habitat, cex=.5, draw="polygon", col=as.character(colvec[3]), alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("EC"))))
    with(habitatN, ordispider(ALL.dist.jtu.jmds, Habitat, cex=.5, draw="polygon", col=as.character(colvec[3]), alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("JC"))))
    with(habitatN, ordispider(ALL.dist.jtu.jmds, Habitat, cex=.5, draw="polygon", col="darkblue", alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("MF"))))
    with(habitatN, ordispider(ALL.dist.jtu.jmds, Habitat, cex=.5, draw="polygon", col="darkblue", alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("NF"))))
    
plot(ALL.dist.jne.jmds, main = "Nestedness beta diversity only", ylim = c(-0.5, 0.5))
    with(habitatN, ordispider(ALL.dist.jne.jmds, Habitat, cex=.5, draw="polygon", col=as.character(colvec[3]), alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("BB"))))
    with(habitatN, ordispider(ALL.dist.jne.jmds, Habitat, cex=.5, draw="polygon", col=as.character(colvec[1]), alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("CL"))))
    with(habitatN, ordispider(ALL.dist.jne.jmds, Habitat, cex=.5, draw="polygon", col=as.character(colvec[3]), alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("EC"))))
    with(habitatN, ordispider(ALL.dist.jne.jmds, Habitat, cex=.5, draw="polygon", col=as.character(colvec[3]), alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("JC"))))
    with(habitatN, ordispider(ALL.dist.jne.jmds, Habitat, cex=.5, draw="polygon", col="darkblue", alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("MF"))))
    with(habitatN, ordispider(ALL.dist.jne.jmds, Habitat, cex=.5, draw="polygon", col="darkblue", alpha=20, kind="se", conf=0.95, label=TRUE, show.groups=(c("NF"))))
    
par(mfrow=c(1,1))

```

# Total beta diversity NMDS is correlated with turnover-only beta diversity 
```{r}
protest(community.jmds, ALL.dist.jtu.jmds)
```

Call:
protest(X = community.jmds, Y = ALL.dist.jtu.jmds) 

Procrustes Sum of Squares (m12 squared):        0.06903 
Correlation in a symmetric Procrustes rotation: 0.9649 
Significance:  0.001 

Permutation: free
Number of permutations: 999

Total beta diversity NMDS is not correlated with nestedness-only beta diversity
```{r}
protest(community.jmds, ALL.dist.jne.jmds)
```

Call:
protest(X = community.jmds, Y = ALL.dist.jne.jmds) 

Procrustes Sum of Squares (m12 squared):        0.9941 
Correlation in a symmetric Procrustes rotation: 0.07677 
Significance:  0.902 

Permutation: free
Number of permutations: 999

# Beta diversity UNCONSTRAINED ordination
############ IMPORTANT #####################################
## For NMDS, mvabund, and boral analyses, remove zerotons and singletons

```{r remove zerotons and singletons from communityB}
communityB <- communityB[, which(specnumber(communityB, MARGIN=2) > 1)]
# 269 species remained

```

## NMDS ordination
```{r NMDS}
### do NMDS analysis to quickly see patterns ####
community.jmds <- metaMDS(communityB, distance = "jaccard", trymax = 40, binary=TRUE)
community.jmds <- metaMDS(communityB, distance = "jaccard", binary = TRUE, previous.best = community.jmds)  # doesn't converge well, with final stress > 0.20
stressplot(community.jmds)
```

## boral
Tested different error families (testing code is archived down below).  Based on residuals, decided on family = "binomial," which is good because the dataset is presence/absence. Using row.effect = "random" to get a composition-only analysis.   Now rerun with many more iterations

# This takes a long time to run, should run overnight
```{r boral high iterations}
# set up MCMC parameters
# mcmc.control <- list(n.burnin = 300, n.iteration = 1000, n.thin = 30, seed = 123) # for debugging

mcmc.control4 <- list(n.burnin = 10000, n.iteration = 40000, n.thin = 30) 

# Set up priors
# Francis Hui suggests trying different priors to stabilise sampling for sparse matrices (such as we have).  This isn't as important as getting the mcmc.control parameters right
#set.prior <- list(type = c("normal","normal","normal","uniform"), hypparams = c(10, 10, 10, 30), ssvs.index = ssvsindex)  
# type = c("normal","normal","normal","uniform"), hypparams = c(10, 10, 10, 30) # boral default
# type = c("cauchy","cauchy","cauchy","uniform"), hypparams = c(2.5^2, 2.5^2, 2.5^2, 30) # Gelman proposed this
# type = c("normal","normal","normal","uniform"), hypparams = c(1, 1, 1, 30) ## People who developed the STAN package proposed this as one possibility. 


# set up model
commB.fit.b3.4.none <- boral(communityB, family = "binomial", num.lv = 2, row.eff = "random", mcmc.control = mcmc.control4, save.model = TRUE); beep(sound = 1)

# save output in case i want to do other analyses on it later
saveRDS(commB.fit.b3.4.none, "boral_commB.fit.b3.4.RDS")
# commB.fit.b3.4.none <- readRDS("boral_commB.fit.b3.4.RDS") # to restore

summary(commB.fit.b3.4.none)
par(mfrow = c(2,2))
plot(commB.fit.b3.4.none) ## Plots used in residual analysis, 
par(mfrow = c(1,1))

commB.fit.b3.4.none.ord <- lvsplot(commB.fit.b3.4.none, biplot=FALSE, col = as.numeric(habitatN$Habitat), return.vals = TRUE)

res.cors <- get.residual.cor(commB.fit.b3.4.none); beep(1) # residual deviation
res.cors$trace
# 4419.197
# habitatN$Elevation_m, y = commB.fit.b3.4.none$lv.iqr[,1]

cor.test(habitatN$Elevation_m, y = commB.fit.b3.4.none$lv.iqr[,1], method = "pearson")
# t = -3.9509, df = 59, p-value = 0.0002106
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval: -0.6359671 -0.2323392
# sample estimates: cor -0.4573986
cor.test(habitatN$Elevation_m, y = commB.fit.b3.4.none$lv.iqr[,1], method = "kendall")
cor.test(habitatN$Elevation_m, y = commB.fit.b3.4.none$lv.iqr[,1], method = "spearman")
# S = 56743, p-value = 4.022e-05
# alternative hypothesis: true rho is not equal to 0
# sample estimates: rho -0.5003503 

cor.test(habitatN$Elevation_m, y = commB.fit.b3.4.none$lv.iqr[,2], method = "pearson")
# t = -5.0463, df = 59, p-value = 4.603e-06
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval: -0.7036107 -0.3449532
#sample estimates: cor -0.5490776 

cor.test(habitatN$Elevation_m, y = commB.fit.b3.4.none$lv.iqr[,2], method = "kendall")
cor.test(habitatN$Elevation_m, y = commB.fit.b3.4.none$lv.iqr[,2], method = "spearman")
# S = 59369, p-value = 1.645e-06
# alternative hypothesis: true rho is not equal to 0
#sample estimates: rho -0.5697854 

```

Try to interpret the latent variables. Latent variables are clearly correlated with the forest types (habitatN$Habitat) but weakly at best correlated with Simpson_evenness_index, Elevation_m, and weather_value. 
*There does seem to be a quadratic relationship between lvs2 and Elevation_m*. *The correlation plot suggests that there are some informative Landsat channels.*  
```{r boral lvs correlations}
cbind(commB.fit.b3.4.none.ord$scaled.lvs,habitatN$Habitat)
par(mfrow = c(1,2))
plot(commB.fit.b3.4.none.ord$scaled.lvs[,1]~habitatN$Habitat)
plot(commB.fit.b3.4.none.ord$scaled.lvs[,2]~habitatN$Habitat)

plot(commB.fit.b3.4.none.ord$scaled.lvs[,1]~habitatN$Simpson_evenness_index)
plot(commB.fit.b3.4.none.ord$scaled.lvs[,2]~habitatN$Simpson_evenness_index)

plot(commB.fit.b3.4.none.ord$scaled.lvs[,1]~habitatN$Elevation_m)
plot(commB.fit.b3.4.none.ord$scaled.lvs[,2]~habitatN$Elevation_m)

plot(commB.fit.b3.4.none.ord$scaled.lvs[,1]~habitatN$weather_value)
plot(commB.fit.b3.4.none.ord$scaled.lvs[,2]~habitatN$weather_value)

# correlation matrix of 2 latent variables (1, 2) with all the Landsat channels. Look only at the two left columns
lvsmatrix <- habitatN %>% dplyr::select(starts_with("x"))
lvsmatrix <- cbind(commB.fit.b3.4.none.ord$scaled.lvs, lvsmatrix)
lvsmatrix_cor <- cor(lvsmatrix)
par(mfrow = c(1,1))
corrplot(lvsmatrix_cor, type = "lower", tl.pos = "l", tl.cex = 0.5, sig.level = 0.05, insig = "blank")

```

## mvabund
Testing whether i can combine levels within habitatN$habitat. I use mvabund to test whether MF and NF are significantly different from each other and from the other habitats:  BB, EC, JC, and CL.  I do this by creating two models, one with all 6 levels and one with NF|MF combined with one of the other two habitats. I run mvabund on both models and use anova to compare the two models. If significantly different, then the two habitat types are significantly different. Finally, i conservatively adjust the p-values for all 15 possible pairwise comparisons (6 * 5)/2. 

*anova.manyglm* options
    *test = "score"* # anova.manyglm help file says that test="wald" is poor for binomial data under some conditions. "score" is the better alternative. 
    *cor.type = "shrink"* # estimates correlations between species, but in an efficient way, which is necessary for our kind of dataset, where there are many more species than there are samples


```{r test if NF is sig diff from other habitats}
# communityB <- communityB[ , 1:150]  # comment away if i want to use the whole dataset.  this is to produce a partial dataset for debugging
communityB.mvb <- mvabund(communityB) 

#nboot <- 499 # set to 20 for debugging (~25 mins for nboot = 499)
nboot <- 999 # set to 999 for publication


# base model with no levels combined
mod_BBCLECJCMFNF.mvb <- manyglm(communityB.mvb ~ Habitat, data = habitatN, family = binomial("cloglog"))
plot(mod_BBCLECJCMFNF.mvb)
anova(mod_BBCLECJCMFNF.mvb, cor.type = "shrink", test = "score", show.time = "all", nBoot = nboot)  # p = 0.001, df = 5, score = 534.8, nBoot = 999, 20 mins.  The Habitat predictor has a sig effect

# combine NF and MF
habitatN$HabitatMFNF <- fct_collapse(habitatN$Habitat, MFNF = c("MF", "NF"))
fct_count(habitatN$HabitatMFNF)

mod_CLBBECJC_MFNF.mvb <- manyglm(communityB.mvb ~ HabitatMFNF, data = habitatN, family = binomial("cloglog"))
plot(mod_CLBBECJC_MFNF.mvb)
anova(mod_BBCLECJCMFNF.mvb, mod_CLBBECJC_MFNF.mvb, cor.type = "shrink", test = "score", show.time = "all", nBoot = nboot) # p = 0.001, df = 1, score= 55.42, nBoot = 999.  MF and NF are sig diff

# combine NF and BB
habitatN$HabitatNFBB <- fct_collapse(habitatN$Habitat, NFBB = c("NF", "BB"))
fct_count(habitatN$HabitatNFBB)

mod_CLECJCMF_NFBB.mvb <- manyglm(communityB.mvb ~ HabitatNFBB, data = habitatN, family = binomial("cloglog"))
plot(mod_CLECJCMF_NFBB.mvb)
anova(mod_BBCLECJCMFNF.mvb, mod_CLECJCMF_NFBB.mvb, cor.type = "shrink", test = "score", show.time = "all", nBoot = nboot)  # p = 0.001, df = 1, score= 54.88, nBoot = 999, 20 mins.  BB and NF are sig diff

# combine NF and JC
habitatN$HabitatNFJC <- fct_collapse(habitatN$Habitat, NFJC = c("NF", "JC"))
fct_count(habitatN$HabitatNFJC)

mod_CLECBBMF_NFJC.mvb <- manyglm(communityB.mvb ~ HabitatNFJC, data = habitatN, family = binomial("cloglog"))
plot(mod_CLECBBMF_NFJC.mvb)
anova(mod_BBCLECJCMFNF.mvb, mod_CLECBBMF_NFJC.mvb, cor.type = "shrink", test = "score", show.time = "all", nBoot = nboot)  # p = 0.001, df = 1, score= 58.09, nBoot = 999, 20 mins.  JC and NF are sig diff

# combine NF and EC
habitatN$HabitatNFEC <- fct_collapse(habitatN$Habitat, NFEC = c("NF", "EC"))
fct_count(habitatN$HabitatNFEC)

mod_CLBBJCMF_NFEC.mvb <- manyglm(communityB.mvb ~ HabitatNFEC, data = habitatN, family = binomial("cloglog"))
plot(mod_CLBBJCMF_NFEC.mvb)
anova(mod_BBCLECJCMFNF.mvb, mod_CLBBJCMF_NFEC.mvb, cor.type = "shrink", test = "score", show.time = "all", nBoot = nboot)  # p = 0.003, df = 1, score= 54.41, nBoot = 999, 20 mins.  EC and NF are sig diff


# combine NF and CL
habitatN$HabitatNFCL <- fct_collapse(habitatN$Habitat, NFCL = c("NF", "CL"))
fct_count(habitatN$HabitatNFCL)

mod_ECBBJCMF_NFCL.mvb <- manyglm(communityB.mvb ~ HabitatNFCL, data = habitatN, family = binomial("cloglog"))
plot(mod_ECBBJCMF_NFCL.mvb)
anova(mod_BBCLECJCMFNF.mvb, mod_ECBBJCMF_NFCL.mvb, cor.type = "shrink", test = "score", show.time = "all", nBoot = nboot)  # p = 0.001, df = 1, score= 64.25, nBoot = 999, 20 mins.  CL and NF are sig diff


## do a table-wide correction, under the assumption that there are 15 possible pairwise comparisons between all 6 forest types:  (5*6)/2 = 15  
pvalues <- c(0.001, .001, .001, .003, .001)
pvalues.corr.fdr<-p.adjust(pvalues, method = "fdr", n = length(pvalues)) 
pvalues.corr.fdr
# 0.00125 0.00125 0.00125 0.00300 0.00125

```


```{r test if MF is sig diff from other habitats}
# communityB <- communityB[ , 1:150]  # comment away if i want to use the whole dataset.  this is to produce a partial dataset for debugging
communityB.mvb <- mvabund(communityB) 

# nboot <- 499 # set to 20 for debugging (~ 20 mins for 499)
nboot <- 999 # set to 999 for publication

# base model with no levels combined:  mod_BBCLECJCMFNF.mvb

# combine NF and MF:  already done above

# combine MF and BB
habitatN$HabitatMFBB <- fct_collapse(habitatN$Habitat, MFBB = c("MF", "BB"))
fct_count(habitatN$HabitatMFBB)

mod_CLECJCNF_MFBB.mvb <- manyglm(communityB.mvb ~ HabitatMFBB, data = habitatN, family = binomial("cloglog"))
plot(mod_CLECJCNF_MFBB.mvb)
anova(mod_BBCLECJCMFNF.mvb, mod_CLECJCNF_MFBB.mvb, cor.type = "shrink", test = "score", show.time = "all", nBoot = nboot)  # p = 0.001, df = 1, score= 54.23, nBoot = 999, 20 mins.  BB and MF are sig diff


# combine MF and JC
habitatN$HabitatMFJC <- fct_collapse(habitatN$Habitat, MFJC = c("MF", "JC"))
fct_count(habitatN$HabitatMFJC)

mod_CLECBBNF_MFJC.mvb <- manyglm(communityB.mvb ~ HabitatMFJC, data = habitatN, family = binomial("cloglog"))
plot(mod_CLECBBNF_MFJC.mvb)
anova(mod_BBCLECJCMFNF.mvb, mod_CLECBBNF_MFJC.mvb, cor.type = "shrink", test = "score", show.time = "all", nBoot = nboot)  # p = 0.001, df = 1, score= 58.73, nBoot = 999, 20 mins.  JC and MF are sig diff


# combine MF and EC
habitatN$HabitatMFEC <- fct_collapse(habitatN$Habitat, MFEC = c("MF", "EC"))
fct_count(habitatN$HabitatMFEC)

mod_CLBBJCNF_MFEC.mvb <- manyglm(communityB.mvb ~ HabitatMFEC, data = habitatN, family = binomial("cloglog"))
plot(mod_CLBBJCNF_MFEC.mvb)
anova(mod_BBCLECJCMFNF.mvb, mod_CLBBJCNF_MFEC.mvb, cor.type = "shrink", test = "score", show.time = "all", nBoot = nboot)  # p = 0.001, df = 1, score= 55.29, nBoot = 999, 20 mins.  EC and MF are sig diff


# combine MF and CL
habitatN$HabitatMFCL <- fct_collapse(habitatN$Habitat, MFCL = c("MF", "CL"))
fct_count(habitatN$HabitatMFCL)

mod_ECBBJCNF_MFCL.mvb <- manyglm(communityB.mvb ~ HabitatMFCL, data = habitatN, family = binomial("cloglog"))
plot(mod_ECBBJCNF_MFCL.mvb)
anova(mod_BBCLECJCMFNF.mvb, mod_ECBBJCNF_MFCL.mvb, cor.type = "shrink", test = "score", show.time = "all", nBoot = nboot)  # p = 0.001, df = 1, score= 71.41, nBoot = 999, 20 mins.  CL and MF are sig diff


# do a table-wide correction, under the assumption that there are 30 possible pairwise comparisons between all 6 forest types:  (5*6)/2 = 15
pvalues <- c(0.001, .001, .001, .001)
pvalues.corr.fdr<-p.adjust(pvalues, method = "fdr", n = length(pvalues)) 
pvalues.corr.fdr 
# [1] 0.001 0.001 0.001 0.001

# pvalues.corr.fdr<-p.adjust(pvalues, method = "fdr", n = length(pvalues))
```

